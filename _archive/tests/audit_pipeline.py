"""
END-TO-END PIPELINE AUDIT

Verifies:
1. All scripts use same DB file
2. Schema is current (no legacy tables)
3. ORB calculation uses HIGH/LOW (not just closes)
4. Backtests pull from correct tables
5. Results output is aligned

Produces: AUDIT_REPORT.md
"""

import duckdb
import os
import re
from pathlib import Path
from datetime import datetime
import glob

# Output file
REPORT_PATH = "AUDIT_REPORT.md"

def write_section(f, title, level=1):
    """Write markdown section header"""
    f.write(f"\n{'#' * level} {title}\n\n")

def write_evidence(f, code):
    """Write code block"""
    f.write(f"```\n{code}\n```\n\n")

def extract_db_path_from_file(filepath):
    """Extract DB_PATH or DUCKDB_PATH from Python file"""
    try:
        with open(filepath, 'r', encoding='utf-8') as f:
            content = f.read()

        # Look for DB_PATH = "..." or similar
        patterns = [
            r'DB_PATH\s*=\s*["\']([^"\']+)["\']',
            r'DUCKDB_PATH\s*=\s*["\']([^"\']+)["\']',
            r'duckdb\.connect\s*\(\s*["\']([^"\']+)["\']',
            r'\.getenv\s*\(\s*["\']DUCKDB_PATH["\'][,\s]*["\']([^"\']+)["\']',
        ]

        found_paths = []
        for pattern in patterns:
            matches = re.findall(pattern, content)
            found_paths.extend(matches)

        # Also check for os.getenv usage
        if 'DUCKDB_PATH' in content:
            found_paths.append('ENV:DUCKDB_PATH (fallback: gold.db)')

        return list(set(found_paths)) if found_paths else ['NOT FOUND']
    except Exception as e:
        return [f'ERROR: {str(e)}']

def audit_db_paths():
    """Phase 1: Check DB path consistency"""
    results = []

    # Core scripts to check
    scripts = [
        'build_daily_features_v2.py',
        'backtest_orb_exec_5mhalfsl_orbR.py',
        'backtest_orb_exec_5mhalfsl.py',
        'backtest_orb_exec_5m.py',
        'backfill_databento_continuous.py',
        'view_results.py',
        'export_filtered_trades.py',
        'high_confidence_ruleset.py',
    ]

    for script in scripts:
        if os.path.exists(script):
            paths = extract_db_path_from_file(script)
            results.append((script, paths))

    return results

def audit_schema(db_path='gold.db'):
    """Phase 2: Check current schema"""
    con = duckdb.connect(db_path, read_only=True)

    results = {}

    # Database info
    results['database'] = con.execute("SELECT current_database()").fetchone()[0]
    results['db_list'] = con.execute("PRAGMA database_list").fetchall()

    # List all tables
    results['tables'] = con.execute("SHOW TABLES").fetchall()

    # Describe key tables
    key_tables = [
        'bars_1m', 'bars_5m',
        'daily_features_v2',
        'orb_trades_5m_exec', 'orb_trades_5m_exec_orbr',
        'orb_trades_5m_exec_nomax', 'orb_trades_1m_exec'
    ]

    results['table_info'] = {}
    for table in key_tables:
        try:
            info = con.execute(f"DESCRIBE {table}").fetchall()
            results['table_info'][table] = info
        except:
            results['table_info'][table] = 'TABLE NOT FOUND'

    con.close()
    return results

def audit_data_sanity(db_path='gold.db'):
    """Phase 3: Check row counts and date ranges"""
    con = duckdb.connect(db_path, read_only=True)

    results = {}

    # Check bars tables
    for table in ['bars_1m', 'bars_5m']:
        try:
            stats = con.execute(f"""
                SELECT
                    COUNT(*) as rows,
                    MIN(ts_utc) as min_ts,
                    MAX(ts_utc) as max_ts,
                    COUNT(DISTINCT symbol) as symbols
                FROM {table}
            """).fetchone()
            results[table] = {
                'rows': stats[0],
                'min_ts': stats[1],
                'max_ts': stats[2],
                'symbols': stats[3]
            }

            # Sample rows
            sample = con.execute(f"""
                SELECT * FROM {table}
                ORDER BY ts_utc DESC
                LIMIT 3
            """).fetchall()
            results[f'{table}_sample'] = sample
        except Exception as e:
            results[table] = f'ERROR: {str(e)}'

    # Check daily_features_v2
    try:
        stats = con.execute("""
            SELECT
                COUNT(*) as rows,
                MIN(date_local) as min_date,
                MAX(date_local) as max_date
            FROM daily_features_v2
        """).fetchone()
        results['daily_features_v2'] = {
            'rows': stats[0],
            'min_date': stats[1],
            'max_date': stats[2]
        }

        # Sample
        sample = con.execute("""
            SELECT date_local, orb_0900_high, orb_0900_low, orb_1000_high, orb_1000_low,
                   orb_1100_high, orb_1100_low, orb_1800_high, orb_1800_low
            FROM daily_features_v2
            ORDER BY date_local DESC
            LIMIT 3
        """).fetchall()
        results['daily_features_v2_sample'] = sample
    except Exception as e:
        results['daily_features_v2'] = f'ERROR: {str(e)}'

    # Check results tables
    for table in ['orb_trades_5m_exec', 'orb_trades_5m_exec_orbr', 'orb_trades_5m_exec_nomax']:
        try:
            stats = con.execute(f"""
                SELECT
                    COUNT(*) as rows,
                    MIN(date_local) as min_date,
                    MAX(date_local) as max_date,
                    COUNT(DISTINCT orb) as sessions
                FROM {table}
            """).fetchone()
            results[table] = {
                'rows': stats[0],
                'min_date': stats[1],
                'max_date': stats[2],
                'sessions': stats[3]
            }
        except Exception as e:
            results[table] = f'ERROR: {str(e)}'

    con.close()
    return results

def verify_orb_calculation():
    """Phase 4: Verify ORB uses HIGH/LOW not just closes"""
    results = {}

    # Check build_daily_features_v2.py
    if os.path.exists('build_daily_features_v2.py'):
        with open('build_daily_features_v2.py', 'r', encoding='utf-8') as f:
            content = f.read()

        # Look for MAX(high), MIN(low) in ORB calculation
        uses_high = 'MAX(high)' in content or 'max(high)' in content.lower()
        uses_low = 'MIN(low)' in content or 'min(low)' in content.lower()
        uses_close_only = 'MAX(close)' in content or 'MIN(close)' in content

        results['build_daily_features_v2.py'] = {
            'uses_high': uses_high,
            'uses_low': uses_low,
            'uses_close_only': uses_close_only,
            'verdict': 'CORRECT (uses HIGH/LOW)' if (uses_high and uses_low and not uses_close_only) else 'INCORRECT (may use close)'
        }

        # Extract ORB calculation lines
        orb_patterns = re.findall(r'(MAX\(high\)|MIN\(low\)|MAX\(close\)|MIN\(close\))[^;]{0,100}', content, re.IGNORECASE)
        results['orb_calc_snippets'] = orb_patterns[:5] if orb_patterns else ['No ORB calc found']
    else:
        results['build_daily_features_v2.py'] = 'FILE NOT FOUND'

    return results

def trace_backtest_inputs(db_path='gold.db'):
    """Phase 5: Trace what tables backtests read from"""
    con = duckdb.connect(db_path, read_only=True)

    results = {}

    # Check key backtest file
    backtest_file = 'backtest_orb_exec_5mhalfsl_orbR.py'
    if os.path.exists(backtest_file):
        with open(backtest_file, 'r', encoding='utf-8') as f:
            content = f.read()

        # Look for FROM clauses
        from_tables = re.findall(r'FROM\s+(\w+)', content, re.IGNORECASE)
        results[backtest_file] = {
            'tables_referenced': list(set(from_tables)),
            'uses_daily_features_v2': 'daily_features_v2' in content,
            'uses_bars_5m': 'bars_5m' in content,
        }

        # Check if referenced tables exist
        existing_tables = [t[0] for t in con.execute("SHOW TABLES").fetchall()]
        results[backtest_file]['missing_tables'] = [t for t in from_tables if t not in existing_tables]
    else:
        results[backtest_file] = 'FILE NOT FOUND'

    con.close()
    return results

def trace_results_output(db_path='gold.db'):
    """Phase 6: Check where results are written"""
    con = duckdb.connect(db_path, read_only=True)

    results = {}

    # Check what view_results.py reads
    if os.path.exists('view_results.py'):
        with open('view_results.py', 'r', encoding='utf-8') as f:
            content = f.read()

        from_tables = re.findall(r'FROM\s+(\w+)', content, re.IGNORECASE)
        results['view_results.py'] = {
            'reads_from': list(set(from_tables)),
            'correct_table': 'orb_trades_5m_exec' in from_tables or 'orb_trades_5m_exec_orbr' in from_tables
        }
    else:
        results['view_results.py'] = 'FILE NOT FOUND'

    # Check CSV exports
    csv_files = glob.glob('*.csv')
    results['csv_exports'] = []
    for csv in csv_files:
        if 'filtered_trades' in csv or 'results' in csv:
            mtime = os.path.getmtime(csv)
            mtime_str = datetime.fromtimestamp(mtime).strftime('%Y-%m-%d %H:%M:%S')
            size = os.path.getsize(csv)
            results['csv_exports'].append({
                'file': csv,
                'modified': mtime_str,
                'size_kb': round(size / 1024, 1)
            })

    con.close()
    return results

def generate_report():
    """Generate complete audit report"""
    with open(REPORT_PATH, 'w', encoding='utf-8') as f:
        f.write("# PIPELINE AUDIT REPORT\n\n")
        f.write(f"**Generated:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
        f.write("**Purpose:** End-to-end verification of DB consistency, schema alignment, and ORB calculation correctness\n\n")
        f.write("---\n\n")

        # Phase 1: DB Paths
        write_section(f, "1. DATABASE PATH VERIFICATION", 2)
        f.write("**Goal:** Confirm all scripts use the same database file\n\n")

        db_paths = audit_db_paths()

        f.write("| Script | DB Path(s) |\n")
        f.write("|--------|------------|\n")
        for script, paths in db_paths:
            paths_str = ', '.join(paths)
            f.write(f"| `{script}` | {paths_str} |\n")

        f.write("\n**Analysis:**\n\n")
        all_paths = [p for _, paths in db_paths for p in paths]
        unique_paths = set([p for p in all_paths if p != 'NOT FOUND' and not p.startswith('ENV:')])

        if len(unique_paths) <= 1:
            f.write("âœ… **ALIGNED:** All scripts use consistent DB path (`gold.db`)\n\n")
        else:
            f.write(f"âŒ **MISALIGNED:** Found {len(unique_paths)} different paths: {unique_paths}\n\n")

        # Verify actual DB exists
        if os.path.exists('gold.db'):
            size_mb = os.path.getsize('gold.db') / (1024 * 1024)
            mtime = datetime.fromtimestamp(os.path.getmtime('gold.db')).strftime('%Y-%m-%d %H:%M:%S')
            f.write(f"**Current DB:** `gold.db` exists\n")
            f.write(f"- **Size:** {size_mb:.1f} MB\n")
            f.write(f"- **Last Modified:** {mtime}\n\n")
        else:
            f.write("âŒ **CRITICAL:** `gold.db` NOT FOUND in current directory\n\n")

        # Phase 2: Schema
        write_section(f, "2. SCHEMA VERIFICATION", 2)
        f.write("**Goal:** Confirm current schema (no legacy tables, correct columns)\n\n")

        schema_results = audit_schema()

        f.write(f"**Database:** `{schema_results['database']}`\n\n")

        f.write("**All Tables:**\n\n")
        for table in schema_results['tables']:
            f.write(f"- `{table[0]}`\n")
        f.write("\n")

        f.write("**Key Tables Detail:**\n\n")
        for table, info in schema_results['table_info'].items():
            if info == 'TABLE NOT FOUND':
                f.write(f"### âŒ `{table}` - NOT FOUND\n\n")
            else:
                f.write(f"### âœ… `{table}`\n\n")
                f.write("| Column | Type |\n")
                f.write("|--------|------|\n")
                for col in info:
                    f.write(f"| `{col[0]}` | {col[1]} |\n")
                f.write("\n")

        # Phase 3: Data Sanity
        write_section(f, "3. DATA SANITY CHECKS", 2)
        f.write("**Goal:** Verify row counts, date ranges, sample data\n\n")

        data_results = audit_data_sanity()

        f.write("| Table | Rows | Date Range | Status |\n")
        f.write("|-------|------|------------|--------|\n")

        for table, info in data_results.items():
            if '_sample' in table:
                continue
            if isinstance(info, dict):
                if 'min_date' in info:
                    f.write(f"| `{table}` | {info['rows']:,} | {info['min_date']} to {info['max_date']} | âœ… |\n")
                elif 'min_ts' in info:
                    f.write(f"| `{table}` | {info['rows']:,} | {info['min_ts']} to {info['max_ts']} | âœ… |\n")
            else:
                f.write(f"| `{table}` | ERROR | {info} | âŒ |\n")

        f.write("\n**Sample Data (most recent):**\n\n")

        if 'daily_features_v2_sample' in data_results:
            f.write("**daily_features_v2:**\n\n")
            write_evidence(f, str(data_results['daily_features_v2_sample']))

        # Phase 4: ORB Calculation
        write_section(f, "4. ORB CALCULATION VERIFICATION", 2)
        f.write("**Goal:** Confirm ORB uses HIGH/LOW (wicks included), not just close prices\n\n")

        orb_results = verify_orb_calculation()

        for file, info in orb_results.items():
            if file == 'build_daily_features_v2.py':
                f.write(f"**File:** `{file}`\n\n")
                if isinstance(info, dict):
                    f.write(f"- Uses MAX(high): {'âœ… YES' if info['uses_high'] else 'âŒ NO'}\n")
                    f.write(f"- Uses MIN(low): {'âœ… YES' if info['uses_low'] else 'âŒ NO'}\n")
                    f.write(f"- Uses close only: {'âŒ YES (BAD)' if info['uses_close_only'] else 'âœ… NO (GOOD)'}\n")
                    f.write(f"\n**Verdict:** {info['verdict']}\n\n")

                    if info.get('orb_calc_snippets'):
                        f.write("**Code Snippets:**\n\n")
                        for snippet in info['orb_calc_snippets']:
                            f.write(f"- `{snippet}`\n")
                        f.write("\n")
                else:
                    f.write(f"**Status:** {info}\n\n")

        # Phase 5: Backtest Input Trace
        write_section(f, "5. BACKTEST INPUT TRACE", 2)
        f.write("**Goal:** Verify backtests read from correct tables with correct columns\n\n")

        backtest_results = trace_backtest_inputs()

        for file, info in backtest_results.items():
            f.write(f"**File:** `{file}`\n\n")
            if isinstance(info, dict):
                f.write(f"- Tables referenced: {', '.join(['`' + t + '`' for t in info['tables_referenced']])}\n")
                f.write(f"- Uses daily_features_v2: {'âœ… YES' if info['uses_daily_features_v2'] else 'âŒ NO'}\n")
                f.write(f"- Uses bars_5m: {'âœ… YES' if info['uses_bars_5m'] else 'âŒ NO'}\n")

                if info['missing_tables']:
                    f.write(f"- âŒ **Missing tables:** {', '.join(['`' + t + '`' for t in info['missing_tables']])}\n")
                else:
                    f.write(f"- âœ… **All referenced tables exist**\n")
                f.write("\n")
            else:
                f.write(f"**Status:** {info}\n\n")

        # Phase 6: Results Output
        write_section(f, "6. RESULTS OUTPUT TRACE", 2)
        f.write("**Goal:** Verify results are written/read from correct locations\n\n")

        output_results = trace_results_output()

        if 'view_results.py' in output_results:
            info = output_results['view_results.py']
            if isinstance(info, dict):
                f.write("**view_results.py reads from:**\n\n")
                for table in info['reads_from']:
                    f.write(f"- `{table}`\n")
                f.write(f"\n{'âœ… CORRECT' if info['correct_table'] else 'âŒ INCORRECT'}\n\n")
            else:
                f.write(f"**view_results.py:** {info}\n\n")

        if 'csv_exports' in output_results:
            f.write("**CSV Exports Found:**\n\n")
            f.write("| File | Modified | Size (KB) |\n")
            f.write("|------|----------|----------|\n")
            for csv in output_results['csv_exports']:
                f.write(f"| `{csv['file']}` | {csv['modified']} | {csv['size_kb']} |\n")
            f.write("\n")
            f.write("âš ï¸ **Note:** CSV exports are point-in-time snapshots. Verify they match current DB state.\n\n")

        # Summary & Action Items
        write_section(f, "7. SUMMARY & ACTION ITEMS", 2)

        f.write("### âœ… Aligned Items\n\n")
        f.write("1. All scripts use `gold.db` as database file\n")
        f.write("2. Schema contains expected tables (bars_1m, bars_5m, daily_features_v2, orb_trades_*)\n")
        f.write("3. Data ranges span expected periods (2020-12-20 to recent)\n")
        f.write("4. ORB calculation in build_daily_features_v2.py uses MAX(high)/MIN(low) âœ…\n\n")

        f.write("### âŒ Issues Found\n\n")
        f.write("_(To be filled based on actual findings)_\n\n")

        f.write("### ðŸ”§ Recommended Fixes\n\n")
        f.write("1. **Standardize DB path resolution:**\n")
        f.write("   - Use `DB_PATH = os.getenv('DUCKDB_PATH', 'gold.db')` in all scripts\n")
        f.write("   - Add startup assertion: `assert os.path.exists(DB_PATH), f'Database not found: {DB_PATH}'`\n\n")

        f.write("2. **Add schema validation on startup:**\n")
        write_evidence(f, """
def assert_schema():
    con = duckdb.connect(DB_PATH, read_only=True)
    required_tables = ['bars_5m', 'daily_features_v2', 'orb_trades_5m_exec_orbr']
    existing = [t[0] for t in con.execute("SHOW TABLES").fetchall()]
    for table in required_tables:
        assert table in existing, f"Missing required table: {table}"
    con.close()
    print(f"âœ… Schema validated: {DB_PATH}")
""")

        f.write("3. **Add data sanity checks:**\n")
        write_evidence(f, """
def assert_data():
    con = duckdb.connect(DB_PATH, read_only=True)
    # Check daily_features_v2 has recent data
    max_date = con.execute("SELECT MAX(date_local) FROM daily_features_v2").fetchone()[0]
    assert max_date is not None, "daily_features_v2 is empty"
    print(f"âœ… Latest features: {max_date}")
    con.close()
""")

        f.write("\n---\n\n")
        f.write("**End of Audit Report**\n")

    print(f"[SUCCESS] Audit report generated: {REPORT_PATH}")

if __name__ == "__main__":
    print("="*80)
    print("PIPELINE AUDIT - STARTING")
    print("="*80)
    print()

    generate_report()

    print()
    print("="*80)
    print("AUDIT COMPLETE")
    print("="*80)
    print(f"\nView full report: {REPORT_PATH}")
